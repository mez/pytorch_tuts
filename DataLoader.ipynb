{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader example\n",
    "Often you'll need train on large datasets. You cannot load and use all of the datapoints, because you'll run out of memory. Hence, you cycle through batches of datapoints. PyTorch has this concept baked in, the following is an example of making use of it. It works in two steps:\n",
    "\n",
    "1. Create a class of that inherits `DataSet`, implement the methods `__ini__()`, `__getitem__()`, and `__len__()`\n",
    "2. Create an instance of `DataLoader` and pass an instance of your `DataSet` into its constructor.\n",
    "\n",
    "** _More info can be found in the docs: [DataLoader](http://pytorch.org/docs/master/data.html)_ **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create DataSet abstraction for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeDataSet(Dataset):\n",
    "    def __init__(self):\n",
    "        super(SomeDataSet, self).__init__()\n",
    "        #download your data etc....\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a DataLoader instance passing in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SomeDataSet()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=64,\n",
    "                         shuffle=True,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use the dataloader instance as a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    for index, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        # train the model below etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
